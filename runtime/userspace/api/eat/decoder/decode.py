# Licensed under the Apache-2.0 license

#!/usr/bin/env python3
"""
Simple COSE Sign1 / EAT Token Decoder

This script decodes COSE Sign1 messages (used for EAT tokens) without requiring
external dependencies like pycose or cbor2. It handles:

1. CBOR tags that wrap the COSE message (like tag 55799 for CWT)
2. COSE Sign1 structure parsing (4-element array)
3. EAT claims analysis with standard claim name mapping
4. Signature extraction and display

Usage:
    python3 decode.py

The script will attempt to decode both:
- example_eat_token.cbor
- structured_eat_token.cbor

Features:
- No external dependencies (pure Python)
- Handles CBOR tags automatically
- Shows standard EAT claim names (iss, cti, nonce, etc.)
- Displays hex dumps for binary data
- Works with OCP EAT tokens generated by the Rust encoder
"""

import os
import struct
import sys
from signature_analysis import analyze_cose_signature, analyze_certificate_headers
from signature_validation import validate_cose_signature

def parse_cbor_header(data, offset=0):
    """Parse CBOR header to understand the structure"""
    if offset >= len(data):
        return None, offset
    
    initial_byte = data[offset]
    major_type = (initial_byte >> 5) & 0x7
    additional_info = initial_byte & 0x1f
    
    offset += 1
    
    # Handle different additional info values
    if additional_info < 24:
        value = additional_info
    elif additional_info == 24:
        value = data[offset]
        offset += 1
    elif additional_info == 25:
        value = struct.unpack('>H', data[offset:offset+2])[0]
        offset += 2
    elif additional_info == 26:
        value = struct.unpack('>I', data[offset:offset+4])[0]
        offset += 4
    elif additional_info == 27:
        value = struct.unpack('>Q', data[offset:offset+8])[0]
        offset += 8
    else:
        value = additional_info
    
    return (major_type, value), offset

def cbor_type_to_string(major_type):
    """Convert CBOR major type number to string name"""
    type_names = {
        0: 'positive_int',
        1: 'negative_int', 
        2: 'byte_string',
        3: 'text_string',
        4: 'array',
        5: 'map',
        6: 'tag',
        7: 'simple'
    }
    return type_names.get(major_type, f'unknown_type_{major_type}')

def parse_cbor_header_with_names(data, offset=0):
    """Parse CBOR header and return named types"""
    header, new_offset = parse_cbor_header(data, offset)
    if header is None:
        return None, offset
    
    major_type, value = header
    type_name = cbor_type_to_string(major_type)
    return (type_name, value), new_offset

def skip_cbor_tags(data):
    """Skip CBOR tags to get to the actual COSE message"""
    offset = 0
    
    while offset < len(data):
        header, new_offset = parse_cbor_header(data, offset)
        if header is None:
            break
            
        major_type, value = header
        
        # Major type 6 is for tags
        if major_type == 6:
            print(f"Found CBOR tag: {value}")
            offset = new_offset
            continue
        else:
            # This is not a tag, so we've found our data
            return data[offset:]
    
    return data

def skip_cbor_array(data, offset, num_elements):
    """Skip over a CBOR array with the given number of elements"""
    for _ in range(num_elements):
        header, offset = parse_cbor_header(data, offset)
        if header:
            offset = skip_cbor_value_simple(data, offset, header[0], header[1])
        else:
            break
    return offset

def skip_cbor_map(data, offset, num_pairs):
    """Skip over a CBOR map with the given number of key-value pairs"""
    for _ in range(num_pairs * 2):  # Each pair has key and value
        header, offset = parse_cbor_header(data, offset)
        if header:
            offset = skip_cbor_value_simple(data, offset, header[0], header[1])
        else:
            break
    return offset

def skip_cbor_value_simple(data, offset, major_type, value):
    """Skip over a CBOR value of any type (simplified version)"""
    if major_type == 0 or major_type == 1 or major_type == 7:  # Integers and primitives
        return offset  # Already consumed
    elif major_type == 2 or major_type == 3:  # Byte string or text string
        return offset + value
    elif major_type == 4:  # Array
        return skip_cbor_array(data, offset, value)
    elif major_type == 5:  # Map
        return skip_cbor_map(data, offset, value)
    elif major_type == 6:  # Tag
        # Skip the tagged value
        header, offset = parse_cbor_header(data, offset)
        if header:
            offset = skip_cbor_value_simple(data, offset, header[0], header[1])
        return offset
    else:
        return offset

def parse_measurement_format(data, offset):
    """Parse MeasurementFormat structure (array format)"""
    try:
        array_info, new_offset = parse_cbor_header_with_names(data, offset)
        if array_info[0] != 'array':
            return f"Expected array, got {array_info[0]}", offset
        
        count = array_info[1]
        result = f"MeasurementFormat array ({count} elements):"
        current_offset = new_offset
        
        for i in range(count):
            if i == 0:
                # First element: content_type (integer)
                item_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                if item_info[0] == 'positive_int':
                    result += f"\n          content_type: {item_info[1]} (CoAP Content-Format)"
                else:
                    result += f"\n          content_type: {item_info}"
            elif i == 1:
                # Second element: concise_evidence (byte string)
                item_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                if item_info[0] == 'byte_string':
                    evidence_data = data[current_offset:current_offset + item_info[1]]
                    current_offset += item_info[1]
                    result += f"\n          concise_evidence: byte_string ({item_info[1]} bytes)"
                    
                    # Show hex dump of first 32 bytes for debugging
                    result += f"\n            Hex dump (first 32 bytes): {evidence_data[:32].hex()}"
                    
                    # Parse the concise evidence (may be tagged with CBOR tag 571)
                    try:
                        evidence_result = parse_concise_evidence(evidence_data, 0)
                        result += f"\n            ConciseEvidence:"
                        result += f"\n              {evidence_result[0]}"
                    except Exception as e:
                        result += f"\n            Failed to parse ConciseEvidence: {e}"
                else:
                    result += f"\n          concise_evidence: {item_info}"
            else:
                # Additional elements
                item_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                result += f"\n          element_{i}: {item_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing MeasurementFormat: {e}", offset

def parse_concise_evidence(data, offset):
    """Parse ConciseEvidence which may be tagged with CBOR tag 571"""
    try:
        # Check if this is tagged concise evidence (CBOR tag 571)
        first_info, new_offset = parse_cbor_header_with_names(data, offset)
        if first_info[0] == 'tag' and first_info[1] == 571:
            # This is tagged concise evidence
            result = f"Tagged ConciseEvidence (CBOR tag 571):"
            map_result = parse_concise_evidence_map(data, new_offset)
            result += f"\n  {map_result[0]}"
            return result, map_result[1]
        else:
            # This is untagged - parse directly as map
            result = f"Untagged ConciseEvidence:"
            map_result = parse_concise_evidence_map(data, offset)
            result += f"\n  {map_result[0]}"
            return result, map_result[1]
    except Exception as e:
        return f"Error parsing ConciseEvidence: {e}", offset

def parse_concise_evidence_map(data, offset):
    """Parse ConciseEvidenceMap structure"""
    try:
        map_info, new_offset = parse_cbor_header_with_names(data, offset)
        if map_info[0] != 'map':
            return f"Expected map, got {map_info[0]}", offset
        
        count = map_info[1]
        result = f"ConciseEvidenceMap with {count} entries:"
        current_offset = new_offset
        
        for i in range(count):
            # Parse key
            key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if key_info[0] == 'positive_int':
                key = key_info[1]
                
                if key == 0:  # environment
                    result += f"\n        environment:"
                    env_result, current_offset = parse_environment_map(data, current_offset)
                    result += f"\n          {env_result}"
                elif key == 1:  # class  
                    result += f"\n        class:"
                    class_result, current_offset = parse_class_map(data, current_offset)
                    result += f"\n          {class_result}"
                elif key == 2:  # measurements
                    result += f"\n        measurements:"
                    meas_result, current_offset = parse_evidence_measurements(data, current_offset)
                    result += f"\n          {meas_result}"
                else:
                    # Parse generic value
                    value_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                    result += f"\n        key_{key}: {value_info}"
            else:
                result += f"\n        key_{key_info}: parsing error"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing ConciseEvidenceMap: {e}", offset

def parse_evidence_measurements(data, offset):
    """Parse evidence measurements array"""
    try:
        value_info, current_offset = parse_cbor_header_with_names(data, offset)
        if value_info[0] != 'array':
            return f"Expected array, got {value_info[0]}", offset
        
        measurements_count = value_info[1]
        result = f"array with {measurements_count} entries"
        
        # Parse each measurement entry
        for j in range(measurements_count):
            meas_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if meas_info[0] == 'array':
                # Parse measurement record array
                meas_array_count = meas_info[1]
                result += f"\n          measurement_{j}: array with {meas_array_count} elements"
                # Typically: [environment-map, [measurement-maps]]
                for k in range(meas_array_count):
                    elem_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                    if elem_info[0] == 'map':
                        result += f"\n            [{k}]: map with {elem_info[1]} entries"
                        # Parse map entries
                        for m in range(elem_info[1]):
                            key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                            val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                            result += f"\n              {key_info} -> {val_info}"
                    elif elem_info[0] == 'array':
                        result += f"\n            [{k}]: array with {elem_info[1]} elements"
                        # Skip array contents for now to avoid infinite recursion
                        for _ in range(elem_info[1]):
                            skip_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                            result += f"\n              array_item: {skip_info}"
                    else:
                        result += f"\n            [{k}]: {elem_info}"
            else:
                result += f"\n          measurement_{j}: {meas_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing evidence measurements: {e}", offset

def parse_class_array_entry(data, offset, class_index):
    """Parse a single class array entry"""
    try:
        class_info, current_offset = parse_cbor_header_with_names(data, offset)
        if class_info[0] != 'array':
            return f"class_{class_index}: {class_info}", offset
        
        array_count = class_info[1] 
        result = f"class_{class_index}: array with {array_count} elements"
        
        for k in range(array_count):
            elem_result, current_offset = parse_class_array_element(data, current_offset, k)
            result += f"\n            {elem_result}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing class array entry {class_index}: {e}", offset

def parse_class_array_element(data, offset, elem_index):
    """Parse elements within a class array"""
    try:
        elem_info, current_offset = parse_cbor_header_with_names(data, offset)
        
        if elem_info[0] == 'map':
            map_result, current_offset = parse_nested_map(data, current_offset, elem_info[1], elem_index)
            return f"[{elem_index}]: {map_result}", current_offset
        elif elem_info[0] == 'array':
            array_result, current_offset = parse_measurement_array(data, current_offset, elem_info[1])
            return f"[{elem_index}]: {array_result}", current_offset
        elif elem_info[0] == 'text_string':
            text_value = data[current_offset:current_offset + elem_info[1]].decode('utf-8', errors='ignore')
            current_offset += elem_info[1]
            return f"[{elem_index}]: '{text_value}'", current_offset
        elif elem_info[0] == 'byte_string':
            bytes_value = data[current_offset:current_offset + elem_info[1]]
            current_offset += elem_info[1]
            return f"[{elem_index}]: bytes({elem_info[1]}) = {bytes_value.hex()}", current_offset
        elif elem_info[0] == 'positive_int':
            return f"[{elem_index}]: {elem_info[1]}", current_offset
        else:
            return f"[{elem_index}]: {elem_info}", current_offset
            
    except Exception as e:
        return f"Error parsing class array element {elem_index}: {e}", offset

def parse_nested_map(data, offset, map_count, context_index):
    """Parse nested maps within class arrays"""
    try:
        result = f"map with {map_count} entries"
        current_offset = offset
        
        for m in range(map_count):
            # Parse key
            key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            key_value = None
            if key_info[0] == 'text_string':
                key_value = data[current_offset:current_offset + key_info[1]].decode('utf-8', errors='ignore')
                current_offset += key_info[1]
            elif key_info[0] == 'positive_int':
                key_value = key_info[1]
            
            # Parse value
            val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if val_info[0] == 'map':
                # Parse ClassMap or similar nested structures
                inner_map_result, current_offset = parse_class_map_fields(data, current_offset, val_info[1])
                result += f"\n              {key_value}: {inner_map_result}"
            elif val_info[0] == 'text_string':
                val_value = data[current_offset:current_offset + val_info[1]].decode('utf-8', errors='ignore')
                current_offset += val_info[1]
                result += f"\n              {key_value}: '{val_value}'"
            elif val_info[0] == 'byte_string':
                val_value = data[current_offset:current_offset + val_info[1]]
                current_offset += val_info[1]
                result += f"\n              {key_value}: bytes = {val_value.hex()}"
            elif val_info[0] == 'positive_int':
                result += f"\n              {key_value}: {val_info[1]}"
            else:
                result += f"\n              {key_value}: {val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing nested map: {e}", offset

def parse_class_map_fields(data, offset, inner_map_count):
    """Parse ClassMap fields with meaningful names"""
    try:
        result = f"map with {inner_map_count} entries"
        current_offset = offset
        
        for n in range(inner_map_count):
            inner_key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            inner_key_value = None
            if inner_key_info[0] == 'text_string':
                inner_key_value = data[current_offset:current_offset + inner_key_info[1]].decode('utf-8', errors='replace')
                current_offset += inner_key_info[1]
            elif inner_key_info[0] == 'positive_int':
                inner_key_value = inner_key_info[1]
            else:
                inner_key_value = f"key_type_{inner_key_info[0]}"
            
            inner_val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            # Map ClassMap keys to meaningful names
            field_name = inner_key_value
            if inner_key_value == 0:
                field_name = "class_id"
            elif inner_key_value == 1:
                field_name = "vendor" 
            elif inner_key_value == 2:
                field_name = "model"
            
            if inner_val_info[0] == 'text_string':
                inner_val_value = data[current_offset:current_offset + inner_val_info[1]].decode('utf-8', errors='replace')
                current_offset += inner_val_info[1]
                result += f"\n                {field_name}: '{inner_val_value}'"
            elif inner_val_info[0] == 'byte_string':
                inner_val_value = data[current_offset:current_offset + inner_val_info[1]]
                current_offset += inner_val_info[1]
                result += f"\n                {field_name}: bytes = {inner_val_value.hex()}"
            elif inner_val_info[0] == 'positive_int':
                result += f"\n                {field_name}: {inner_val_info[1]}"
            elif inner_val_info[0] == 'tag':
                # Handle CBOR tags (like tag 111 for class_id)
                tag_num = inner_val_info[1] 
                tagged_content, current_offset = parse_cbor_header_with_names(data, current_offset)
                if tagged_content[0] in ['text_string', 'byte_string']:
                    tagged_value = data[current_offset:current_offset + tagged_content[1]].decode('utf-8', errors='replace')
                    current_offset += tagged_content[1]
                    result += f"\n                {field_name}: '{tagged_value}' (tag {tag_num})"
                else:
                    result += f"\n                {field_name}: tag({tag_num}) -> {tagged_content}"
            else:
                result += f"\n                {field_name}: {inner_val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing class map fields: {e}", offset

def parse_measurement_array(data, offset, array_elem_count):
    """Parse measurement arrays within environment maps"""
    try:
        result = f"array with {array_elem_count} elements"
        current_offset = offset
        
        for j in range(array_elem_count):
            measurement_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if measurement_info[0] == 'map':
                # Parse measurement map with detailed structure
                meas_result, current_offset = parse_measurement_map_detailed(data, current_offset, measurement_info[1], j)
                result += f"\n              {meas_result}"
            elif measurement_info[0] == 'array':
                # Parse nested measurement arrays
                nested_result, current_offset = parse_nested_measurement_array(data, current_offset, measurement_info[1], j)
                result += f"\n              {nested_result}"
            elif measurement_info[0] == 'text_string':
                text_val = data[current_offset:current_offset + measurement_info[1]].decode('utf-8', errors='replace')
                current_offset += measurement_info[1]
                result += f"\n              measurement_{j}: '{text_val}'"
            elif measurement_info[0] == 'byte_string':
                bytes_val = data[current_offset:current_offset + measurement_info[1]]
                current_offset += measurement_info[1]
                result += f"\n              measurement_{j}: bytes = {bytes_val.hex()}"
            elif measurement_info[0] == 'positive_int':
                result += f"\n              measurement_{j}: {measurement_info[1]}"
            elif measurement_info[0] == 'negative_int':
                result += f"\n              measurement_{j}: {-measurement_info[1] - 1}"
            else:
                result += f"\n              measurement_{j}: {measurement_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing measurement array: {e}", offset

def parse_measurement_map_detailed(data, offset, meas_map_count, meas_index):
    """Parse detailed measurement map structure"""
    try:
        result = f"measurement_{meas_index}: map with {meas_map_count} entries"
        current_offset = offset
        
        for mm in range(meas_map_count):
            # Parse measurement key
            meas_key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if meas_key_info[0] == 'positive_int':
                meas_key_value = meas_key_info[1]
                # Map measurement keys to names
                if meas_key_value == 0:
                    meas_key_name = "mkey"
                elif meas_key_value == 1:
                    meas_key_name = "mval"
                else:
                    meas_key_name = f"key_{meas_key_value}"
            elif meas_key_info[0] == 'text_string':
                meas_key_name = data[current_offset:current_offset + meas_key_info[1]].decode('utf-8', errors='replace')
                current_offset += meas_key_info[1]
            else:
                meas_key_name = str(meas_key_info)
            
            # Parse measurement value
            meas_val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if meas_val_info[0] == 'map':
                # Parse the map contents (firmware measurement details)
                mval_result, current_offset = parse_measurement_value_map(data, current_offset, meas_val_info[1], meas_key_name)
                result += f"\n                {mval_result}"
            elif meas_val_info[0] == 'byte_string':
                meas_val_data = data[current_offset:current_offset + meas_val_info[1]]
                current_offset += meas_val_info[1]
                try:
                    meas_val_str = meas_val_data.decode('utf-8', errors='replace')
                    result += f"\n                {meas_key_name}: '{meas_val_str}'"
                except:
                    result += f"\n                {meas_key_name}: bytes = {meas_val_data.hex()}"
            elif meas_val_info[0] == 'text_string':
                meas_val_str = data[current_offset:current_offset + meas_val_info[1]].decode('utf-8', errors='replace')
                current_offset += meas_val_info[1]
                result += f"\n                {meas_key_name}: '{meas_val_str}'"
            elif meas_val_info[0] == 'positive_int':
                result += f"\n                {meas_key_name}: {meas_val_info[1]}"
            else:
                result += f"\n                {meas_key_name}: {meas_val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing measurement map {meas_index}: {e}", offset

def parse_measurement_value_map(data, offset, mval_map_count, field_name):
    """Parse measurement value map with field details"""
    try:
        result = f"{field_name}: map with {mval_map_count} entries"
        current_offset = offset
        
        for mv in range(mval_map_count):
            # Parse map key
            mv_key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if mv_key_info[0] == 'positive_int':
                mv_key_value = mv_key_info[1]
                # Common measurement value keys
                if mv_key_value == 0:
                    mv_key_name = "version"
                elif mv_key_value == 1:
                    mv_key_name = "svn"
                elif mv_key_value == 2:
                    mv_key_name = "digests"
                elif mv_key_value == 3:
                    mv_key_name = "flags"
                elif mv_key_value == 4:
                    mv_key_name = "raw_value"
                elif mv_key_value == 14:
                    mv_key_name = "integrity_registers"
                else:
                    mv_key_name = f"field_{mv_key_value}"
            elif mv_key_info[0] == 'text_string':
                mv_key_name = data[current_offset:current_offset + mv_key_info[1]].decode('utf-8', errors='replace')
                current_offset += mv_key_info[1]
            else:
                mv_key_name = str(mv_key_info)
            
            # Parse map value
            mv_val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if mv_val_info[0] == 'text_string':
                mv_val_str = data[current_offset:current_offset + mv_val_info[1]].decode('utf-8', errors='replace')
                current_offset += mv_val_info[1]
                result += f"\n                  {mv_key_name}: '{mv_val_str}'"
            elif mv_val_info[0] == 'byte_string':
                mv_val_bytes = data[current_offset:current_offset + mv_val_info[1]]
                current_offset += mv_val_info[1]
                result += f"\n                  {mv_key_name}: bytes = {mv_val_bytes.hex()}"
            elif mv_val_info[0] == 'positive_int':
                result += f"\n                  {mv_key_name}: {mv_val_info[1]}"
            elif mv_val_info[0] == 'array':
                # Parse arrays like signer_id or integrity registers
                array_result, current_offset = parse_measurement_value_array(data, current_offset, mv_val_info[1], mv_key_name)
                result += f"\n                  {array_result}"
            elif mv_val_info[0] == 'map' and mv_key_name == "integrity_registers":
                # Parse integrity registers map
                ir_result, current_offset = parse_integrity_registers_map(data, current_offset, mv_val_info[1])
                result += f"\n                  {ir_result}"
            else:
                result += f"\n                  {mv_key_name}: {mv_val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing measurement value map: {e}", offset

def parse_measurement_value_array(data, offset, mv_array_count, field_name):
    """Parse arrays within measurement values (like signer_id)"""
    try:
        result = f"{field_name}: array with {mv_array_count} elements"
        current_offset = offset
        
        for mvx in range(mv_array_count):
            mvx_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if mvx_info[0] == 'text_string':
                mvx_val = data[current_offset:current_offset + mvx_info[1]].decode('utf-8', errors='replace')
                current_offset += mvx_info[1]
                result += f"\n                    [{mvx}]: '{mvx_val}'"
            elif mvx_info[0] == 'byte_string':
                mvx_bytes = data[current_offset:current_offset + mvx_info[1]]
                current_offset += mvx_info[1]
                result += f"\n                    [{mvx}]: bytes = {mvx_bytes.hex()}"
            elif mvx_info[0] == 'positive_int':
                result += f"\n                    [{mvx}]: {mvx_info[1]}"
            elif mvx_info[0] == 'negative_int':
                result += f"\n                    [{mvx}]: {-mvx_info[1] - 1}"
            elif mvx_info[0] == 'array':
                # Parse nested arrays within signer_id
                nested_result, current_offset = parse_nested_array_elements(data, current_offset, mvx_info[1], mvx)
                result += f"\n                    {nested_result}"
            else:
                result += f"\n                    [{mvx}]: {mvx_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing measurement value array: {e}", offset

def parse_nested_array_elements(data, offset, mvx_sub_count, parent_index):
    """Parse nested array elements within measurement arrays"""
    try:
        result = f"[{parent_index}]: array with {mvx_sub_count} elements"
        current_offset = offset
        
        for mvxs in range(mvx_sub_count):
            mvxs_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if mvxs_info[0] == 'negative_int':
                result += f"\n                      [{mvxs}]: {-mvxs_info[1] - 1}"
            elif mvxs_info[0] == 'byte_string':
                mvxs_bytes = data[current_offset:current_offset + mvxs_info[1]]
                current_offset += mvxs_info[1]
                result += f"\n                      [{mvxs}]: bytes = {mvxs_bytes.hex()}"
            elif mvxs_info[0] == 'text_string':
                mvxs_val = data[current_offset:current_offset + mvxs_info[1]].decode('utf-8', errors='replace')
                current_offset += mvxs_info[1]
                result += f"\n                      [{mvxs}]: '{mvxs_val}'"
            else:
                result += f"\n                      [{mvxs}]: {mvxs_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing nested array elements: {e}", offset

def parse_integrity_registers_map(data, offset, ir_map_count):
    """Parse integrity registers map structure"""
    try:
        result = f"integrity_registers: map with {ir_map_count} entries"
        current_offset = offset
        
        for ir in range(ir_map_count):
            # Parse register ID (key)
            reg_id_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            reg_id_name = "unknown"
            if reg_id_info[0] == 'positive_int':
                reg_id_name = f"register_{reg_id_info[1]}"
            elif reg_id_info[0] == 'text_string':
                reg_id_name = data[current_offset:current_offset + reg_id_info[1]].decode('utf-8', errors='replace')
                current_offset += reg_id_info[1]
            
            # Parse digests array (value)
            reg_val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if reg_val_info[0] == 'array':
                digest_count = reg_val_info[1]
                result += f"\n                    {reg_id_name}: array with {digest_count} digests"
                for dig in range(digest_count):
                    # Parse digest entry [alg_id, value]
                    digest_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                    if digest_info[0] == 'array' and digest_info[1] == 2:
                        digest_result, current_offset = parse_digest_entry(data, current_offset, dig)
                        result += f"\n                      {digest_result}"
                    else:
                        result += f"\n                      digest_{dig}: {digest_info}"
            else:
                result += f"\n                    {reg_id_name}: {reg_val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing integrity registers map: {e}", offset

def parse_digest_entry(data, offset, digest_index):
    """Parse individual digest entries with algorithm and value"""
    try:
        # Parse algorithm ID
        alg_info, current_offset = parse_cbor_header_with_names(data, offset)
        alg_name = "unknown"
        if alg_info[0] == 'negative_int':
            alg_id = -alg_info[1] - 1
            if alg_id == -16:
                alg_name = "SHA-256"
            elif alg_id == -43:
                alg_name = "SHA-384"
            elif alg_id == -44:
                alg_name = "SHA-512"
            else:
                alg_name = f"alg_{alg_id}"
        
        # Parse digest value
        val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
        if val_info[0] == 'byte_string':
            digest_bytes = data[current_offset:current_offset + val_info[1]]
            current_offset += val_info[1]
            result = f"digest_{digest_index}: {alg_name} = {digest_bytes.hex()}"
        else:
            result = f"digest_{digest_index}: {alg_name} = {val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing digest entry {digest_index}: {e}", offset

def parse_nested_measurement_array(data, offset, meas_sub_array_count, meas_index):
    """Parse nested measurement arrays"""
    try:
        result = f"measurement_{meas_index}: array with {meas_sub_array_count} elements"
        current_offset = offset
        
        for msub in range(meas_sub_array_count):
            msub_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            if msub_info[0] == 'text_string':
                msub_val = data[current_offset:current_offset + msub_info[1]].decode('utf-8', errors='replace')
                current_offset += msub_info[1]
                result += f"\n                [{msub}]: '{msub_val}'"
            elif msub_info[0] == 'byte_string':
                msub_bytes = data[current_offset:current_offset + msub_info[1]]
                current_offset += msub_info[1]
                result += f"\n                [{msub}]: bytes = {msub_bytes.hex()}"
            elif msub_info[0] == 'positive_int':
                result += f"\n                [{msub}]: {msub_info[1]}"
            elif msub_info[0] == 'negative_int':
                result += f"\n                [{msub}]: {-msub_info[1] - 1}"
            elif msub_info[0] == 'map':
                # Parse simple map structures
                msub_map_result, current_offset = parse_simple_map(data, current_offset, msub_info[1], msub)
                result += f"\n                {msub_map_result}"
            else:
                result += f"\n                [{msub}]: {msub_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing nested measurement array: {e}", offset

def parse_simple_map(data, offset, msub_map_count, elem_index):
    """Parse simple map structures within arrays"""
    try:
        result = f"[{elem_index}]: map with {msub_map_count} entries"
        current_offset = offset
        
        for msmap in range(msub_map_count):
            msmap_key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            msmap_val_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            
            msmap_key_name = "unknown"
            if msmap_key_info[0] == 'positive_int':
                if msmap_key_info[1] == 0:
                    msmap_key_name = "mkey"
                elif msmap_key_info[1] == 1:
                    msmap_key_name = "mval"
            elif msmap_key_info[0] == 'text_string':
                msmap_key_name = data[current_offset-msmap_key_info[1]:current_offset].decode('utf-8', errors='replace')
            
            if msmap_val_info[0] == 'text_string':
                msmap_val = data[current_offset:current_offset + msmap_val_info[1]].decode('utf-8', errors='replace')
                current_offset += msmap_val_info[1]
                result += f"\n                  {msmap_key_name}: '{msmap_val}'"
            else:
                result += f"\n                  {msmap_key_name}: {msmap_val_info}"
        
        return result, current_offset
        
    except Exception as e:
        return f"Error parsing simple map: {e}", offset

def parse_environment_map(data, offset):
    """Parse an EnvironmentMap structure (now modular)"""
    try:
        map_info, new_offset = parse_cbor_header_with_names(data, offset)
        if map_info[0] != 'map':
            return f"Expected map, got {map_info[0]}", offset
        
        count = map_info[1]
        result = f"EnvironmentMap with {count} entries:"
        current_offset = new_offset
        
        for i in range(count):
            # Parse key
            key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if key_info[0] == 'positive_int':
                key = key_info[1]
                
                if key == 0:  # class
                    # Parse value
                    value_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                    if value_info[0] == 'array':
                        class_count = value_info[1]
                        result += f"\n          class: array with {class_count} entries"
                        # Parse each class entry using modular functions
                        for j in range(class_count):
                            class_result, current_offset = parse_class_array_entry(data, current_offset, j)
                            result += f"\n            {class_result}"
                    else:
                        result += f"\n          class: {value_info}"
                else:
                    # Parse generic value
                    value_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                    result += f"\n          key_{key}: {value_info}"
            else:
                result += f"\n          key_{key_info}: parsing error"
                
        return result, current_offset
                        
    except Exception as e:
        return f"Error parsing EnvironmentMap: {e}", offset

def parse_class_map(data, offset):
    """Parse a ClassMap structure"""
    try:
        map_info, new_offset = parse_cbor_header_with_names(data, offset)
        if map_info[0] != 'map':
            return f"Expected map, got {map_info[0]}", offset
        
        count = map_info[1]
        result = f"ClassMap with {count} entries:"
        current_offset = new_offset
        
        for i in range(count):
            # Parse key
            key_info, current_offset = parse_cbor_header_with_names(data, current_offset)
            if key_info[0] == 'positive_int':
                key = key_info[1]
                
                # Parse value
                value_info, current_offset = parse_cbor_header_with_names(data, current_offset)
                
                if key == 0:  # class_id
                    result += f"\n          class_id: {value_info}"
                elif key == 1:  # vendor
                    result += f"\n          vendor: {value_info}"
                elif key == 2:  # model
                    result += f"\n          model: {value_info}"
                else:
                    result += f"\n          key_{key}: {value_info}"
            else:
                result += f"\n          key_{key_info}: parsing error"
                        
        return result, current_offset
                        
    except Exception as e:
        return f"Error parsing ClassMap: {e}", offset

def parse_measurements_array(data, offset, num_elements):
    """Parse measurements array"""
    try:
        print(f"              measurements: array ({num_elements} elements)")
        for elem_idx in range(num_elements):
            print(f"                Measurement {elem_idx + 1}:")
            header, offset = parse_cbor_header(data, offset)
            if header:
                offset = skip_cbor_value_simple(data, offset, header[0], header[1])
                
    except Exception as e:
        print(f"              Error parsing measurements: {e}")
        
    return offset

def get_concise_evidence_key_name(key):
    """Get names for ConciseEvidenceMap keys"""
    keys = {
        0: "environment",
        1: "measurements",
    }
    return keys.get(key, f"key_{key}")

def get_cbor_type_name(major_type):
    """Get readable name for CBOR major types"""
    types = {
        0: "positive_integer",
        1: "negative_integer", 
        2: "byte_string",
        3: "text_string",
        4: "array",
        5: "map",
        6: "tag",
        7: "primitive"
    }
    return types.get(major_type, f"type_{major_type}")

def get_eat_claim_name(key):
    """Get the standard name for EAT claim keys (matching eat_encoder.rs constants)"""
    eat_claims = {
        # Standard CWT/EAT claims
        1: "iss (Issuer)",
        2: "sub (Subject)", 
        3: "aud (Audience)",
        4: "exp (Expiration Time)",
        5: "nbf (Not Before)",
        6: "iat (Issued At)",
        7: "cti (CWT ID)",
        8: "cnf (Confirmation)",
        10: "nonce",
        
        # EAT-specific claims
        256: "ueid (Universal Entity ID)",
        257: "sueids (Semi-permanent UEIDs)",
        258: "oemid (OEM ID)",
        259: "hwmodel (Hardware Model)",
        260: "hwversion (Hardware Version)",
        261: "uptime (Uptime)",
        262: "swversion (Software Version)",
        263: "dbgstat (Debug Status)",
        264: "location",
        265: "eat_profile (EAT Profile)",
        266: "profile (Profile)",
        267: "bootcount (Boot Count)",
        268: "bootseed (Boot Seed)",
        269: "dloas (DLOA)",
        273: "measurements (Evidence)",
        
        # Private/custom claims
        -70001: "rim_locators (RIM Locators)",
        -70002: "private_claim_1",
        -70003: "private_claim_2", 
        -70004: "private_claim_3",
        -70005: "private_claim_4",
        -70006: "private_claim_5",
    }
    return eat_claims.get(key, f"claim-{key}")

def parse_cose_protected_headers(data, offset):
    """Parse COSE Sign1 protected headers"""
    header, new_offset = parse_cbor_header(data, offset)
    if header and header[0] == 2:  # Byte string
        protected_len = header[1]
        protected_headers = data[new_offset:new_offset+protected_len]
        print(f"Protected headers ({protected_len} bytes): {protected_headers.hex()}")
        return new_offset + protected_len
    return offset

def parse_cose_protected_headers_with_data(data, offset):
    """Parse COSE Sign1 protected headers and return data"""
    header, new_offset = parse_cbor_header(data, offset)
    if header and header[0] == 2:  # Byte string
        protected_len = header[1]
        protected_headers = data[new_offset:new_offset+protected_len]
        print(f"Protected headers ({protected_len} bytes): {protected_headers.hex()}")
        return new_offset + protected_len, protected_headers
    return offset, None

def parse_cose_unprotected_headers(data, offset):
    """Parse COSE Sign1 unprotected headers"""
    header, new_offset = parse_cbor_header(data, offset)
    if header and header[0] == 5:  # Map
        map_pairs = header[1]
        print(f"Unprotected headers: map with {map_pairs} pairs")
        # Parse the map content
        current_offset = new_offset
        for _ in range(map_pairs):  # key-value pairs
            # Parse key
            key_header, current_offset = parse_cbor_header(data, current_offset)
            key_value = None
            if key_header and key_header[0] == 0:  # Positive integer
                key_value = key_header[1]
            
            # Parse value
            value_header, current_offset = parse_cbor_header(data, current_offset)
            if value_header and value_header[0] == 2:  # Byte string
                value_data = data[current_offset:current_offset+value_header[1]]
                current_offset += value_header[1]
                
                print(f"  Key {key_value}: {len(value_data)} bytes")
                # Check if this is a certificate (X5CHAIN)
                if analyze_certificate_headers(key_value, value_data):
                    print(f"    Certificate analysis completed")
                else:
                    print(f"    Data: {value_data[:16].hex()}{'...' if len(value_data) > 16 else ''}")
            
        return current_offset
    return offset

def parse_cose_unprotected_headers_with_data(data, offset):
    """Parse COSE Sign1 unprotected headers and return certificate data"""
    header, new_offset = parse_cbor_header(data, offset)
    certificate_data = None
    
    if header and header[0] == 5:  # Map
        map_pairs = header[1]
        print(f"Unprotected headers: map with {map_pairs} pairs")
        # Parse the map content
        current_offset = new_offset
        for _ in range(map_pairs):  # key-value pairs
            # Parse key
            key_header, current_offset = parse_cbor_header(data, current_offset)
            key_value = None
            if key_header and key_header[0] == 0:  # Positive integer
                key_value = key_header[1]
            
            # Parse value
            value_header, current_offset = parse_cbor_header(data, current_offset)
            if value_header and value_header[0] == 2:  # Byte string
                value_data = data[current_offset:current_offset+value_header[1]]
                current_offset += value_header[1]
                
                print(f"  Key {key_value}: {len(value_data)} bytes")
                # Check if this is a certificate (X5CHAIN)
                if analyze_certificate_headers(key_value, value_data):
                    print(f"    Certificate analysis completed")
                    if key_value == 33:  # X5CHAIN
                        certificate_data = value_data
                else:
                    print(f"    Data: {value_data[:16].hex()}{'...' if len(value_data) > 16 else ''}")
            
        return current_offset, certificate_data
    return offset, None

def parse_cose_signature(data, offset):
    """Parse COSE Sign1 signature"""
    if offset < len(data):
        header, new_offset = parse_cbor_header(data, offset)
        if header and header[0] == 2:  # Byte string
            signature_len = header[1]
            signature = data[new_offset:new_offset+signature_len]
            print(f"Signature ({signature_len} bytes): {signature.hex()}")
            # Enhanced signature analysis
            analyze_cose_signature(signature)
            return new_offset + signature_len
    return offset

def parse_eat_profile_claim(payload, claims_offset, value_info):
    """Parse EAT Profile claim (265) with CBOR tag"""
    print(f"    Value: CBOR tag ({value_info})")
    if value_info == 111:  # OID tag
        print(f"      Tag type: OID (111)")
    
    # Parse the tagged value
    tag_value_header, new_offset = parse_cbor_header(payload, claims_offset)
    if tag_value_header:
        if tag_value_header[0] == 3:  # Text string
            profile_len = tag_value_header[1]
            profile_value = payload[new_offset:new_offset+profile_len].decode('utf-8')
            print(f"      EAT Profile OID: '{profile_value}'")
            return new_offset + profile_len
        elif tag_value_header[0] == 2:  # Byte string
            profile_len = tag_value_header[1]
            profile_bytes = payload[new_offset:new_offset+profile_len]
            profile_value = profile_bytes.decode('utf-8')
            print(f"      EAT Profile OID: '{profile_value}'")
            return new_offset + profile_len
        else:
            print(f"      Tagged value: {get_cbor_type_name(tag_value_header[0])}")
            return skip_cbor_value_simple(payload, new_offset, tag_value_header[0], tag_value_header[1])
    else:
        print(f"      Could not parse tagged value")
        return claims_offset

def parse_measurements_claim(payload, claims_offset, value_info):
    """Parse measurements claim (273) array"""
    print(f"    Value: measurements array ({value_info} elements)")
    current_offset = claims_offset
    
    # Parse each measurement format in the array
    for meas_idx in range(value_info):
        print(f"      Measurement {meas_idx + 1}:")
        result, current_offset = parse_measurement_format(payload, current_offset)
        print(f"        {result}")
    
    return current_offset

def parse_generic_claim_value(payload, claims_offset, value_type, value_info):
    """Parse generic claim values based on CBOR type"""
    if value_type == 2:  # Byte string
        if value_info <= 32:  # Show short byte strings in hex
            byte_data = payload[claims_offset:claims_offset+value_info]
            print(f"    Value: byte string ({value_info} bytes): {byte_data.hex()}")
        else:
            print(f"    Value: byte string ({value_info} bytes)")
        return claims_offset + value_info
    elif value_type == 3:  # Text string
        text_value = payload[claims_offset:claims_offset+value_info].decode('utf-8')
        print(f"    Value: text string = '{text_value}'")
        return claims_offset + value_info
    elif value_type == 0:  # Positive integer
        print(f"    Value: positive integer = {value_info}")
        return claims_offset
    elif value_type == 1:  # Negative integer
        print(f"    Value: negative integer = {-value_info - 1}")
        return claims_offset
    elif value_type == 4:  # Array (generic)
        print(f"    Value: array ({value_info} elements)")
        return skip_cbor_array(payload, claims_offset, value_info)
    elif value_type == 5:  # Map
        print(f"    Value: map ({value_info} pairs)")
        return skip_cbor_map(payload, claims_offset, value_info)
    elif value_type == 6:  # Tag (generic)
        print(f"    Value: CBOR tag ({value_info})")
        # Skip other tagged values
        tag_value_header, new_offset = parse_cbor_header(payload, claims_offset)
        if tag_value_header:
            return skip_cbor_value_simple(payload, new_offset, tag_value_header[0], tag_value_header[1])
        return claims_offset
    else:
        print(f"    Value: unknown type {value_type}")
        return claims_offset

def parse_eat_claims(payload):
    """Parse EAT claims from payload"""
    print("\n=== EAT Claims Analysis ===")
    claims_offset = 0
    claims_header, claims_offset = parse_cbor_header(payload, claims_offset)
    
    if not (claims_header and claims_header[0] == 5):  # Map
        print("EAT payload is not a CBOR map")
        return
    
    num_claims = claims_header[1]
    print(f"EAT claims: map with {num_claims} entries")
    
    # Parse each claim
    for i in range(num_claims):
        # Parse key
        key_header, claims_offset = parse_cbor_header(payload, claims_offset)
        if not key_header:
            continue
            
        key = None
        if key_header[0] == 0:  # Positive integer key
            key = key_header[1]
            claim_name = get_eat_claim_name(key)
            print(f"  Claim {i+1}: {claim_name} (key={key})")
        elif key_header[0] == 3:  # Text string key
            key_len = key_header[1]
            key = payload[claims_offset:claims_offset+key_len].decode('utf-8')
            claims_offset += key_len
            print(f"  Claim {i+1}: '{key}' (string key)")
        else:
            print(f"  Claim {i+1}: Key = unknown type {key_header[0]}")
        
        # Parse value with special handling for specific claims
        value_header, new_offset = parse_cbor_header(payload, claims_offset)
        if not value_header:
            continue
            
        value_type = value_header[0]
        value_info = value_header[1]
        
        # Special handling for specific claims
        if key == 273 and value_type == 4:  # Measurements array
            claims_offset = parse_measurements_claim(payload, new_offset, value_info)
        elif key == 265 and value_type == 6:  # EAT Profile tag
            claims_offset = parse_eat_profile_claim(payload, new_offset, value_info)
        else:
            # Generic claim value parsing
            claims_offset = parse_generic_claim_value(payload, new_offset, value_type, value_info)

def parse_cose_payload(data, offset):
    """Parse COSE Sign1 payload and return new offset"""
    header, new_offset = parse_cbor_header(data, offset)
    if not (header and header[0] == 2):  # Byte string
        return offset
        
    payload_len = header[1]
    payload = data[new_offset:new_offset+payload_len]
    print(f"Payload ({payload_len} bytes)")
    print(f"Payload first 64 bytes: {payload[:64].hex()}")
    
    # Try to parse payload as CBOR
    try:
        parse_eat_claims(payload)
    except Exception as e:
        print(f"Could not parse EAT claims: {e}")
        import traceback
        traceback.print_exc()
    
    return new_offset + payload_len

def parse_cose_payload_with_data(data, offset):
    """Parse COSE Sign1 payload and return data"""
    header, new_offset = parse_cbor_header(data, offset)
    if not (header and header[0] == 2):  # Byte string
        return offset, None
        
    payload_len = header[1]
    payload = data[new_offset:new_offset+payload_len]
    print(f"Payload ({payload_len} bytes)")
    print(f"Payload first 64 bytes: {payload[:64].hex()}")
    
    # Try to parse payload as CBOR
    try:
        parse_eat_claims(payload)
    except Exception as e:
        print(f"Could not parse EAT claims: {e}")
        import traceback
        traceback.print_exc()
    
    return new_offset + payload_len, payload

def parse_cose_signature_with_data(data, offset):
    """Parse COSE Sign1 signature and return data"""
    if offset < len(data):
        header, new_offset = parse_cbor_header(data, offset)
        if header and header[0] == 2:  # Byte string
            signature_len = header[1]
            signature = data[new_offset:new_offset+signature_len]
            print(f"Signature ({signature_len} bytes): {signature.hex()}")
            # Enhanced signature analysis
            analyze_cose_signature(signature)
            return signature
    return None

def parse_cose_sign1_structure(cose_data):
    """Parse the main COSE Sign1 structure"""
    print("\n=== COSE Sign1 Structure Analysis ===")
    offset = 0
    
    # Parse the main array structure
    header, offset = parse_cbor_header(cose_data, offset)
    if not header:
        print("Could not parse COSE structure header")
        return
        
    major_type, array_length = header
    if major_type != 4:  # Array
        print(f"Unexpected CBOR structure: major type {major_type}")
        return
        
    print(f"COSE Sign1 array with {array_length} elements")
    
    # Store data for signature validation
    validation_data = {}
    
    # Element 1: Protected headers (bstr)
    offset, protected_headers = parse_cose_protected_headers_with_data(cose_data, offset)
    validation_data['protected_headers'] = protected_headers
    
    # Element 2: Unprotected headers (map)
    offset, certificate = parse_cose_unprotected_headers_with_data(cose_data, offset)
    validation_data['certificate'] = certificate
    
    # Element 3: Payload (bstr)
    offset, payload = parse_cose_payload_with_data(cose_data, offset)
    validation_data['payload'] = payload
    
    # Element 4: Signature (bstr)
    signature = parse_cose_signature_with_data(cose_data, offset)
    validation_data['signature'] = signature
    
    # Perform signature validation if we have all the data
    if all(key in validation_data and validation_data[key] is not None 
           for key in ['protected_headers', 'payload', 'signature', 'certificate']):
        validate_cose_signature(
            validation_data['protected_headers'],
            validation_data['payload'], 
            validation_data['signature'],
            validation_data['certificate']
        )

def decode_eat_token(file_path):
    """Decode an EAT token that may be wrapped in CBOR tags"""
    if not os.path.exists(file_path):
        print(f"Error: File '{file_path}' not found in the current directory.")
        print(f"Current directory: {os.getcwd()}")
        return
    
    try:
        with open(file_path, "rb") as f:
            data = f.read()
        
        print(f"File size: {len(data)} bytes")
        print(f"First 16 bytes (hex): {data[:16].hex()}")
        
        # Skip any CBOR tags to get to the COSE message
        cose_data = skip_cbor_tags(data)
        
        if len(cose_data) != len(data):
            print(f"Skipped {len(data) - len(cose_data)} bytes of CBOR tags")
            print(f"COSE data first 16 bytes: {cose_data[:16].hex()}")
        
        # Parse the COSE Sign1 structure
        parse_cose_sign1_structure(cose_data)
        
    except Exception as e:
        print(f"Error decoding file: {e}")
        import traceback
        traceback.print_exc()

def main():
    """Main function to decode EAT tokens from command line arguments"""
    
    if len(sys.argv) < 2:
        print("Usage: python3 decode.py <eat_token_file>")
        print("Example: python3 decode.py example_eat_token.cbor")
        sys.exit(1)
    
    file_path = sys.argv[1]
    print(f"=== Decoding {file_path} ===")
    decode_eat_token(file_path)

if __name__ == "__main__":
    main()